{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to accompany article by Arseniev-Koehler and Foster, \"Teaching an algorithm what it means to be fat: machine-learning as a model for cultural learning.\" All code last checked on Python 3 in Windows 5/30/2018. Please cite our paper or [GitHub repo](https://github.com/arsena-k/Word2Vec-bias-extraction) if reused. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Model Training, Perfomance Evaluation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:** In this Jupyter notebook, we train a Word2Vec model of text data using Gensim.  Word2Vec models words in a text dataset as numeric vectors. For a review of Word2Vec check out this [blog post](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/). We also include code in this notebook to evaluate model quality on the Google Analogy Test on any trained Word2Vec model, and explore any trained Word2Vec model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents**\n",
    "\n",
    "* Part 1: [Train a Word2Vec model on some text data](#Train)\n",
    "* Part 2: [Test your model's quality using the Google Analogy Test](#Accuracy)\n",
    "* Part 3: [Explore and visualize your Word2Vec model](#Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tips for getting started:**\n",
    "* Suggestions along the way for dataset to use for Part 1 (training), or a pre-trained model to jump into model accuracy and exploration (Part 2) and skip training in Part 1. \n",
    "* This notebook was written in Python 3\n",
    "* Install needed packages, especially make sure you have installed Cython\n",
    "* Know where this Jupyter Notebook is saved on your computer. That folder will be called your \"working directory\", and it is where we will keep all models and data files. If you save a model, it will save there. If you download a dataset or pretrained model, you should save the file to there: when loading in files, Juputer Notebook will look in your working directory for that file by default. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import external functions and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alina Arseniev\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import cython #ENSURE cython package is installed on computer/canopy\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import phrases \n",
    "from gensim import corpora, models, similarities #calc all similarities at once, from http://radimrehurek.com/gensim/tut3.html\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "import csv\n",
    "from statistics import mean\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import pandas as pd\n",
    "import string\n",
    "from string import digits\n",
    "import re\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#np.set_printoptions(threshold=np.inf) #set to print full output\n",
    "\n",
    "#if you don't have any of these, or get an error, you will need to install them first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Train'></a> \n",
    "## Part 1: Train a Word2Vec Model, Explore Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't have a dataset? \n",
    "\n",
    "Gensim has a few free suggestions, such as the [Text8 Corpus](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Text8Corpus)\n",
    "    \n",
    "Or, download this free Kaggle dataset of 3 million news headlines from the [Examiner](https://www.kaggle.com/therohk/examine-the-examiner/version/3)  and clean for Word2Vec using code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20100101</td>\n",
       "      <td>100 most anticipated books releasing 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20100101</td>\n",
       "      <td>10 best films of 2009 what s on your list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20100101</td>\n",
       "      <td>10 days of free admission at lan su chinese ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20100101</td>\n",
       "      <td>10 playstation games to watch out for 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20100101</td>\n",
       "      <td>10 resolutions for a happy new year for you an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20100101</td>\n",
       "      <td>10 tips to a healthy diet that works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20100101</td>\n",
       "      <td>10 tips to avoid the drive thru and encourage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20100101</td>\n",
       "      <td>10 trends to end 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20100101</td>\n",
       "      <td>11 year old girl and 15 year old boy accused o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20100101</td>\n",
       "      <td>12 days of rotoff vijay singh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20100101</td>\n",
       "      <td>12 new year s resolutions for better eating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20100101</td>\n",
       "      <td>14 hours of energy conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2009 entertainment farewells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2009 review climategate to copenhagen part i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2009 review lacrosse inches into the mainstream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2009 s best pet moments for me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2009 sprint cup season review clint bowyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2009 the year viral videos a retospective cove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2009 top 10 christian fiction atlanta based au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2009 was adam lambert s year to star 2010 shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2009 was a year of great tunes and great shows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2009 weather highlights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2010 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2010 and beyond beyond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2010 a new year and a new decade dawns what dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2010 a space fairy tale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2010 a whole new year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2010 a year of races gop gov race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2010 ball drop video from times square happy n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20100101</td>\n",
       "      <td>2010 california fishing license no wear initia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089751</th>\n",
       "      <td>20151231</td>\n",
       "      <td>the strongest trump supporters are registered ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089752</th>\n",
       "      <td>20151231</td>\n",
       "      <td>the wsj reports the nsa spied on israeli prime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089753</th>\n",
       "      <td>20151231</td>\n",
       "      <td>the year of the eater entrepreneur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089754</th>\n",
       "      <td>20151231</td>\n",
       "      <td>the year review impressive wines and wineries ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089755</th>\n",
       "      <td>20151231</td>\n",
       "      <td>the young and the restless spoilers ashley abb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089756</th>\n",
       "      <td>20151231</td>\n",
       "      <td>tips for successful achievement of new year re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089757</th>\n",
       "      <td>20151231</td>\n",
       "      <td>tonya couch brought back to us from mexico whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089758</th>\n",
       "      <td>20151231</td>\n",
       "      <td>top 10 beers of 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089759</th>\n",
       "      <td>20151231</td>\n",
       "      <td>top carson aides resign from failing campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089760</th>\n",
       "      <td>20151231</td>\n",
       "      <td>top five healthier snack options for the new year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089761</th>\n",
       "      <td>20151231</td>\n",
       "      <td>top stories of 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089762</th>\n",
       "      <td>20151231</td>\n",
       "      <td>toshiba and times square welcome 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089763</th>\n",
       "      <td>20151231</td>\n",
       "      <td>towering inferno erupts at dubai luxury hotel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089764</th>\n",
       "      <td>20151231</td>\n",
       "      <td>toy plane chants islamic prayer instead of jet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089765</th>\n",
       "      <td>20151231</td>\n",
       "      <td>tv actor wayne rogers has died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089766</th>\n",
       "      <td>20151231</td>\n",
       "      <td>uber hits milestone 1 billion rides given by r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089767</th>\n",
       "      <td>20151231</td>\n",
       "      <td>useful tech gifts on secret wish lists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089768</th>\n",
       "      <td>20151231</td>\n",
       "      <td>utah sports top 5 coolest people of 2015 they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089769</th>\n",
       "      <td>20151231</td>\n",
       "      <td>utah sports top 5 morons of 2015 see if you ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089770</th>\n",
       "      <td>20151231</td>\n",
       "      <td>utah sports top story of 2015 utah state f dav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089771</th>\n",
       "      <td>20151231</td>\n",
       "      <td>vaginal estrogen can improve postmenopausal se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089772</th>\n",
       "      <td>20151231</td>\n",
       "      <td>vegas fun the 2015 ford mustang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089773</th>\n",
       "      <td>20151231</td>\n",
       "      <td>wallethub s 16 financial resolutions for the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089774</th>\n",
       "      <td>20151231</td>\n",
       "      <td>what did we learn from the 49ers 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089775</th>\n",
       "      <td>20151231</td>\n",
       "      <td>what lies ahead for hartford hockey 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089776</th>\n",
       "      <td>20151231</td>\n",
       "      <td>which is better investment lego bricks or gold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089777</th>\n",
       "      <td>20151231</td>\n",
       "      <td>wild score three unanswered goals to defeat th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089778</th>\n",
       "      <td>20151231</td>\n",
       "      <td>with nasa and russia on the sidelines europe i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089779</th>\n",
       "      <td>20151231</td>\n",
       "      <td>wolf pack battling opponents officials on the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089780</th>\n",
       "      <td>20151231</td>\n",
       "      <td>writespace hosts all genre open mic night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3089781 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         publish_date                                    headline_tokens\n",
       "0            20100101          100 most anticipated books releasing 2010\n",
       "1            20100101          10 best films of 2009 what s on your list\n",
       "2            20100101  10 days of free admission at lan su chinese ga...\n",
       "3            20100101         10 playstation games to watch out for 2010\n",
       "4            20100101  10 resolutions for a happy new year for you an...\n",
       "5            20100101               10 tips to a healthy diet that works\n",
       "6            20100101  10 tips to avoid the drive thru and encourage ...\n",
       "7            20100101                              10 trends to end 2010\n",
       "8            20100101  11 year old girl and 15 year old boy accused o...\n",
       "9            20100101                      12 days of rotoff vijay singh\n",
       "10           20100101        12 new year s resolutions for better eating\n",
       "11           20100101                      14 hours of energy conference\n",
       "12           20100101                       2009 entertainment farewells\n",
       "13           20100101       2009 review climategate to copenhagen part i\n",
       "14           20100101    2009 review lacrosse inches into the mainstream\n",
       "15           20100101                     2009 s best pet moments for me\n",
       "16           20100101         2009 sprint cup season review clint bowyer\n",
       "17           20100101  2009 the year viral videos a retospective cove...\n",
       "18           20100101  2009 top 10 christian fiction atlanta based au...\n",
       "19           20100101  2009 was adam lambert s year to star 2010 shou...\n",
       "20           20100101     2009 was a year of great tunes and great shows\n",
       "21           20100101                            2009 weather highlights\n",
       "22           20100101                                             2010 1\n",
       "23           20100101                             2010 and beyond beyond\n",
       "24           20100101  2010 a new year and a new decade dawns what dr...\n",
       "25           20100101                            2010 a space fairy tale\n",
       "26           20100101                              2010 a whole new year\n",
       "27           20100101                  2010 a year of races gop gov race\n",
       "28           20100101  2010 ball drop video from times square happy n...\n",
       "29           20100101  2010 california fishing license no wear initia...\n",
       "...               ...                                                ...\n",
       "3089751      20151231  the strongest trump supporters are registered ...\n",
       "3089752      20151231  the wsj reports the nsa spied on israeli prime...\n",
       "3089753      20151231                 the year of the eater entrepreneur\n",
       "3089754      20151231  the year review impressive wines and wineries ...\n",
       "3089755      20151231  the young and the restless spoilers ashley abb...\n",
       "3089756      20151231  tips for successful achievement of new year re...\n",
       "3089757      20151231  tonya couch brought back to us from mexico whi...\n",
       "3089758      20151231                               top 10 beers of 2015\n",
       "3089759      20151231      top carson aides resign from failing campaign\n",
       "3089760      20151231  top five healthier snack options for the new year\n",
       "3089761      20151231                                top stories of 2015\n",
       "3089762      20151231              toshiba and times square welcome 2016\n",
       "3089763      20151231  towering inferno erupts at dubai luxury hotel ...\n",
       "3089764      20151231  toy plane chants islamic prayer instead of jet...\n",
       "3089765      20151231                     tv actor wayne rogers has died\n",
       "3089766      20151231  uber hits milestone 1 billion rides given by r...\n",
       "3089767      20151231             useful tech gifts on secret wish lists\n",
       "3089768      20151231  utah sports top 5 coolest people of 2015 they ...\n",
       "3089769      20151231  utah sports top 5 morons of 2015 see if you ma...\n",
       "3089770      20151231  utah sports top story of 2015 utah state f dav...\n",
       "3089771      20151231  vaginal estrogen can improve postmenopausal se...\n",
       "3089772      20151231                    vegas fun the 2015 ford mustang\n",
       "3089773      20151231  wallethub s 16 financial resolutions for the n...\n",
       "3089774      20151231              what did we learn from the 49ers 2015\n",
       "3089775      20151231           what lies ahead for hartford hockey 2016\n",
       "3089776      20151231  which is better investment lego bricks or gold...\n",
       "3089777      20151231  wild score three unanswered goals to defeat th...\n",
       "3089778      20151231  with nasa and russia on the sidelines europe i...\n",
       "3089779      20151231  wolf pack battling opponents officials on the ...\n",
       "3089780      20151231          writespace hosts all genre open mic night\n",
       "\n",
       "[3089781 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat= pd.read_csv('examiner-date-tokens.csv') #this file should be in your working directory - the same folder where this Jupyter Notebook is saved\n",
    "dat #view what it looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocessing and Cleaning* \n",
    "\n",
    "From visually looking at the data, it is already pretty clean. Most importantly, letters are all lowercased, and punctuation removed. But we'll need to remove digits. And, the corpus needs to be re-structured for Word2Vec into a list of \"sentences\" or, in this case, headlines. Within each \"sentence\" we'll tokenize the string such that each word is a token.\n",
    "\n",
    "*Fake original text data, before being cleaned and pre-processed might have looked something like this:*\n",
    "\n",
    "    mydata= [These are words in the First sentence. These are words in the Second sentence! These are words in the Third sentence.] \n",
    "    \n",
    "*We want to clean it to be an object like this:*\n",
    "\n",
    "    sentences= [[these, are, words, in, the first, sentence], [these, are, words, in, the , second, sentence], [these, are, words, in, the , third, sentence]]\n",
    "\n",
    "\n",
    "More subjective choices for pre-processing in natural language processing commonly include removing stop words (words that are frequent but sometime considered meaningless, such as \"the\") and stemming words (e.g., reducing all words to a single tense, like \"running and \"runs\" to \"run\"). I do not remove stop words, since I do not buy that these are always \"meaningless,\" and from my understanding of Word2Vec, it is well equipped to extract any meaning from stop words if it is there (i.e., if it predicts other words' meaning), or place little emphasis on stop words (or noise) if they do not predict other words' meaning. Further, I do not stem words, since I see the endings of words as information. On smaller datasets stemming can be a strategy to reduce the vocabulary size and increase the number of instances of each vocabulary word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best', 'films', 'of', 'what', 's', 'on', 'your', 'list']\n",
      "3089781\n"
     ]
    }
   ],
   "source": [
    "dat2= [str(i[1]) for i in dat.values] #only need the text of each headline in the 1st index, not the date, in the 0th index\n",
    "translator = str.maketrans(string.ascii_letters, string.ascii_letters, string.digits)\n",
    "\n",
    "sentences=[]\n",
    "for i in dat2:\n",
    "    headline= i.translate(translator)\n",
    "    headline= headline.strip()\n",
    "    sentences.append(headline.split())\n",
    "    \n",
    "print(sentences[1])\n",
    "print(len(sentences)) # check that it is actually around 3 million headlines here as supposed to be. its ok if not perfectly clean (i.e.  some words that are nonsensical) for these purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#does sentences look ok? then delete dat and dat2 to save up some space\n",
    "del(dat2)\n",
    "del(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have your own dataset? Load it below. \n",
    "\n",
    "Note your sentences object should be an object of cleaned, pre-processed, tokenized text data, as described above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences= open('your_tokenized_data_file_here.txt').read() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we'll train a Word2Vec model on our sentences object. Here are some hyperparameters involved:\n",
    "\n",
    "* For a review see [Rong 2014](https://arxiv.org/abs/1411.2738)  and the [Gensim documentation](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "\n",
    "Key hyperparameters for Word2Vec include the learning architecture (Skip Gram or Context Bag of Words), the dimensionality of the word-vectors we will learn, and the context window of words, \"window\". Skip-gram sets up the artificial neural network underlying Word2Vec to predict set of context words given a target word. CBOW, or Context Bag of Words, sets up the network to predict a target word given a set of context words. The number of context words used is set by the \"window\" parameter. \n",
    "\n",
    "* size = word vector dimensionality. usually ranges 50-500 with gains in model performance diminishing after 300 (Mikolov et al. 2013a). I've seen up to 1000, but usually see 100, 300, and sometimes 500 dimensions on larger corprora. If you have a smaller dataset, stick to smaller dimensionality, roughly 50-200. Even 100 dimensions is a lot to learn! And, if you are using the embeddings for a classifiation task down the road, it might be better to keep dimensionality low. \n",
    "* min_count = minimum word count. Any word that does not occur at least this many times across all documents is ignored. Default is 5. I often set this higher to learn only high quality word-vectors. \n",
    "* workers = number of threads to run in parallel, I set to 4. This speeds up training a lot, but to use make sure Cython is installed first. \n",
    "* window = context window size. This is the numebr of words used to predict a target word (in CBOW) or to be predicted from a target word (SG). A larger window captures topical similarity, smaller captures is semantic similarity (Goldberg 2016, Levy and Goldberg 2014).\n",
    "* seed= can set a seed for reproducibility, note you also cannot use multiple workers if you want a fully reproducible model.\n",
    "* sg = learning architecture: skip-gram (1) or CBOW (0). Skip-gram sets up the artificial neural network underlying Word2Vec to predict set of context words given a target word. CBOW, or Context Bag of Words, sets up the network to predict a target word given a set of context words. \n",
    "* hs= training algorithm to speed up computations: hierarchical softmax (1) or negative sampling (0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Models with Four Combos of Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a few combos of hyperparameters and see which performs best on your dataset by evaluating their accuracy in Part 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run bigram transformer, below, if you want bigrams (two-word phrases that are meaningful, like \"New York\"). This needs to be done before training the Word2Vec model. You can run one more times, such as to catch three-grams (like \"New York City\"), take a look at [Gensim documentaion for examples](https://radimrehurek.com/gensim/models/phrases.html).\n",
    "\n",
    "If you only want single word-tokens, then just use \"sentences\" when you feed into Word2Vec() rather than feeding in bigram_transformer[sentences] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your \"sentences\" object with the cleaned text data. \n",
    "bigram_transformer = phrases.Phrases(sentences) \n",
    "bigram= phrases.Phraser(bigram_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try training models A, B, C, or D, which vary by learning architecture (Skip Gram vs Context Bag of Words) and training algorithm (negative sampling vs hierarchical softmax).\n",
    "Try other paramters, too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelA_ALLYEARS= word2vec.Word2Vec(bigram[sentences], workers=4, sg=0,size=500, min_count=40,window=5, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelB_ALLYEARS= word2vec.Word2Vec(bigram[sentences], workers=4, sg=1, size=500, min_count=40, window=10, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelC_ALLYEARS= word2vec.Word2Vec(bigram[sentences],  workers=4, sg=0, hs=1,size=500, min_count=40, window=10, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelD_ALLYEARS= word2vec.Word2Vec(bigram[sentences], workers=4, sg=1, hs=1, size=500, min_count=40, window=10, sample=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your model to your working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelA_ALLYEARS.init_sims(replace=True) #Precompute L2-normalized vectors. If replace is set to TRUE, forget the original vectors and only keep the normalized ones. Saves lots of memory, but can't continue to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelA_ALLYEARS.save(\"modelA\") #save your model for later use! change the name to something to remember the hyperparameters you trained it with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Accuracy'></a> \n",
    "## Part 2: Word2Vec Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Google Analogy Test** is one of the most accepted strategies to evaluate how \"good\" or high quality your model is. The Google Analogy Test includes a series of analogies divided up into 15 subsections, including world capitals, countries’ currencies, family, and a series of syntactic sections such as tense and plurality.  For example, an analogy in the semantic section of World Capitals will include: “Berlin: Germany as Paris: ?” and if the model responds correctly it will return: “France.” An analogy in the semantic section of family will include: “Mother: Father as Daughter: Son.” In the syntax section with tense, a sample analogy might be “Walk: Walked as Run: Ran.”  The Google Analogy test includes a total of 20,000 questions, and accuracy is the proportion of these questions that the model answers correctly. A \"better\" model should answer more questions correctly. As we'll see, this isn't the best measure but it is a good starting point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload your saved, trained model you want to evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "currentmodel=  Word2Vec.load(\"modelA\") #name of YOUR model here, or file path to your model.\n",
    "\n",
    "#currentmodel=  Word2Vec.load(\"Word2VecModels/modelA_ALLYEARS_500dim_10CW\") #name of YOUR model here, or file path to your model. this is set for Alina's computer\n",
    "\n",
    "#    An example for a PC computer if your model is in your downloads folder, and you're using a model named \"modelA_ALLYEARS_500dim_10CW\" \n",
    "#currentmodel=  Word2Vec.load(\"C:/Users/Alina Arseniev/Downloads/modelA_ALLYEARS_500dim_10CW\")\n",
    "\n",
    "#   An example for a Mac if your model is in your downloads folder, and you're using a model named \"modelA_ALLYEARS_500dim_10CW\" \n",
    "#currentmodel=  Word2Vec.load(\"~/Downloads/modelA_ALLYEARS_500dim_10CW\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, download a pre-trained model on GoogleNews, find link to download on this [site](https://code.google.com/archive/p/word2vec/) or direct link to [download here](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing). Extract the files, and make sure you have the one called \"GoogleNews-vectors-negative300.bin.gz\" in your working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "currentmodel = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "#   An example for a PC computer if your model is in your downloads folder, and you're using the Google model \n",
    "#currentmodel=  KeyedVectors.load_word2vec_format('C:/Users/Alina Arseniev/Downloads/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "#   An example for a Mac if your model is in your downloads folder, and you're using the Google model \n",
    "#currentmodel=  KeyedVectors.load_word2vec_format(\"~/Downloads/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the model accuracy on the Google Analogy Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on world_capitals1: 0.0\n",
      "Accuracy on world_capitals2: 0.0\n",
      "Accuracy on money: 0.0\n",
      "Accuracy on US_capitals: 0.0\n",
      "Accuracy on family: 0.0\n",
      "Accuracy on adj_to_adverbs: 0.0\n",
      "Accuracy on opposites: 0.0\n",
      "Accuracy on comparative: 0.0\n",
      "Accuracy on superlative: 0.0\n",
      "Accuracy on present_participle: 0.0\n",
      "Accuracy on nationality: 0.0011792452830188679\n",
      "Accuracy on past_tense: 0.0\n",
      "Accuracy on plural: 0.0\n",
      "Accuracy on plural_verbs: 0.0\n",
      "Accuracy on world_capitals3: 0.00010662117496534811\n",
      "\u001b[1mAverage Accuracy: 8.572443053228107e-05\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Make sure you have downloaded three files into your working directory from this from the Github repo https://github.com/arsena-k/Word2Vec-bias-extraction: questions_words_pasted.txt, testing.py, and question-words.txt\n",
    "accuracy=currentmodel.wv.accuracy('questions_words_pasted.txt') \n",
    "\n",
    "accuracy_labels= ['world_capitals1', 'world_capitals2', 'money', 'US_capitals', 'family', 'adj_to_adverbs', 'opposites', 'comparative', 'superlative','present_participle', 'nationality', 'past_tense', 'plural', 'plural_verbs', 'world_capitals3']\n",
    "\n",
    "accuracy_tracker=[]\n",
    "for i in range(0, len(accuracy)):\n",
    "    sum_corr = len(accuracy[i]['correct'])\n",
    "    sum_incorr = len(accuracy[i]['incorrect'])\n",
    "    total = sum_corr + sum_incorr\n",
    "    print(\"Accuracy on \" + str(accuracy_labels[i]) + \": \"  + str(float(sum_corr)/(total)))\n",
    "    accuracy_tracker.append(float(sum_corr)/(total))\n",
    "\n",
    "print('\\033[1m' + \"Average Accuracy: \" + str(mean(accuracy_tracker)) + '\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes on the Google Analogy Test:*\n",
    "\n",
    "When originally published, Word2Vec averaged at around 60% across all sections of the Google Analogy Test. Models I've trained on a large news corpus tend to average between 50 and 60%. On smaller coropora, or more heterogenous corpora, accuracy rates might even hover around 0. The Google Analogy test is a useful benchmark, but may be more or less meaningful on different datasets. For example, we might not expect it provide useful infomration on a historical dataset, which contains different language and knoweldge (e.g., some currencies and capitals were likely different at the time the data was produced). For some datasets, it may be useful to select certain sections that are more meaninful than others, such as dropping the section on money for a data set on narratives. \n",
    "\n",
    "Even with low performance on this test, vectors might still contain meaningful, interesting information, but might not be robust or high quality enough for more complex tasks. You can also try twweaking the hyperparameters used to improve performance, especially the dimensionality, context window, and learning architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Results'></a> \n",
    "## Part 3: Explore and Visualize your Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're jumping right to here and didn't go though Part 2, look at first few lines of [Part 2](#Accuracy) for help to upload your own trained model or a pre-trained model you want to explore. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many vocabulary words were learned by the model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(currentmodel.wv.vocab) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the raw word-vector for 'woman'. These numbers aren't so meaninful to human readers on their own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "currentmodel['woman'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most similar words to \"woman\"? What are the cosine simiarlties? \n",
    "\n",
    "* Cosine Similarity ranges 0-1 here, with 0 corresponding to two words that share NOTHING in common, and 1 suggesting they are the exact same meaning. For a review on cosine similarity for word-vector models, see this [article](http://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/). \n",
    "* Surprised that a word like \"man\" is so similar to \"woman\"? While these two are opposites in terms of gender, otherwise they correpond to largely the same meaning (adults, humans, singular, nouns, etc.), so they should be very similar and close in space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shasta', 0.19185668230056763),\n",
       " ('grain', 0.17193982005119324),\n",
       " ('darien', 0.1698988378047943),\n",
       " ('lentils', 0.16366681456565857),\n",
       " ('emily_maynard', 0.1633109152317047),\n",
       " ('discovery_channel', 0.16314801573753357),\n",
       " ('lightly', 0.15895523130893707),\n",
       " ('health_scare', 0.15843741595745087),\n",
       " ('ybor_city', 0.15725888311862946),\n",
       " ('missing_boy', 0.15360340476036072)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentmodel.most_similar('man', topn=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate cosine similarity of two words specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766401228292\n"
     ]
    }
   ],
   "source": [
    "print(1 - spatial.distance.cosine(currentmodel['woman'], currentmodel['man'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which words are FARTHEST from big? Doesn't work so well, results aren't usually meaninful. This shows how distance as can break down as a meaningful measure in this model compared to our intuitions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('D.Earnhardt_Jr._###-###', 0.38161107897758484),\n",
       " ('M.Martin_###-###', 0.37538671493530273),\n",
       " ('G.Biffle_###-###', 0.3698088824748993),\n",
       " ('NewsTrack_Sports', 0.3603689968585968),\n",
       " ('J.Gordon_###-###', 0.3462575674057007),\n",
       " ('----------_-----------------------------------------------_GS##',\n",
       "  0.3396575152873993),\n",
       " ('Ky.Busch_##-###', 0.3247494101524353),\n",
       " ('E.Sadler_###-###', 0.3226693868637085),\n",
       " ('J.McMurray_###-###', 0.3169156610965729),\n",
       " ('By_SEAN_BARRON', 0.315515398979187)]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentmodel.most_similar(negative=['big']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some tricks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask our model to solve the anaology, man is to king as woman is to ? \n",
    "\n",
    "Specifically, we ask the model to find the word-vector that is most similar to the vector leftover from the vector algebra: king + woman - man\n",
    "\n",
    "Another way to think about our expected relationship is:\n",
    "* A queen is a *feminine* king. \n",
    "* If we take *woman* and subtract *man*, we get just the parts that about being feminine, since we subtracted out parts that are shared between men and woman (e.g., being a human, adult, noun, singular, etc.). \n",
    "* If we take away the masculinity from king (subtract man), and add the femininity (add woman), we get the feminine version of a king- a queen! \n",
    "\n",
    "If you're model doesn't solve this correctly, try a few other tricks to see if it gets those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118192911148071), ('monarch', 0.6189674139022827), ('princess', 0.5902431607246399), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321243286133), ('kings', 0.5236844420433044), ('Queen_Consort', 0.5235945582389832), ('queens', 0.5181134343147278), ('sultan', 0.5098593235015869), ('monarchy', 0.5087411999702454)]\n"
     ]
    }
   ],
   "source": [
    "print(currentmodel.wv.most_similar(positive=['woman', 'king'], negative=['man'])) #man:king as woman:_?___ QUEEN! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try another analogy: boy is to man as girl is to? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('boy', 0.874837338924408), ('teenager', 0.6932151913642883), ('teenage_girl', 0.6277071237564087), ('lad', 0.6241019368171692), ('kid', 0.6167631149291992), ('schoolboy', 0.6000924110412598), ('teen_ager', 0.5852149724960327), ('boys', 0.5807874202728271), ('youngster', 0.5773991346359253), ('guy', 0.5459756851196289)]\n"
     ]
    }
   ],
   "source": [
    "print(currentmodel.wv.most_similar(positive=['girl', 'man'], negative=['woman'])) #boy:man as girl:_?___ WOMAN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A trickier trick! Can Word2Vec which word doesn't match? It should be able to tell based on which word has the lowest cosine similarity to all the other words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noodle'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentmodel.doesnt_match(\"noodle chicken turkey beef\".split()) #does it get that noodle is not a meat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toe'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentmodel.doesnt_match(\"tomato potato toe\".split()) #does it get that a toe is not a fruit or veggie?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the most \"feminine\" and \"masculine\" words\n",
    "\n",
    "*Like how we asked Word2Vec to solve the anaology of king and queen, we're going to isolate gender. \n",
    "*If we take woman and subtract man, we get just the parts that about being feminine, since we subtracted out parts that are shared between men and woman (e.g., being a human, adult, noun, singular, etc.). Now we're asking what are the most similar words to this leftover vector, that represents femininity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('she', 0.45412713289260864), ('her', 0.39712798595428467), ('Certified_Nurse_Midwife', 0.3824717700481415), ('Ms.', 0.37514764070510864), ('silicone_gel_implant', 0.3704040050506592), ('girlhood', 0.37001776695251465), ('nurse_midwife', 0.369699090719223), ('undergo_hysterectomy', 0.36893025040626526), ('silicone_breast_implants', 0.3683786988258362), ('breastfeeds', 0.36699435114860535)]\n"
     ]
    }
   ],
   "source": [
    "print(currentmodel.wv.most_similar(positive=['woman'], negative=['man'], topn=10)) #what are the most feminine words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Shaun_Maloney_Aiden_McGeady', 0.3502722382545471), ('tactically_adept', 0.3487197458744049), ('Matt_Bramald', 0.3400961458683014), ('strongside_LB', 0.3376367688179016), ('newboy', 0.33329281210899353), ('Philip_Boampong', 0.3315233886241913), ('joker', 0.3312978744506836), ('superpest', 0.330258846282959), ('TRENDING_UP', 0.33007559180259705), ('Felipe_Claybrooks', 0.3289524018764496)]\n"
     ]
    }
   ],
   "source": [
    "print(currentmodel.wv.most_similar(positive=['man'], negative=['woman'], topn=10)) #what are the most masculine words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize Word-Vector Neighborhoods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try visualizing a set of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_word_list=[]\n",
    "my_word_vectors=[]\n",
    "label=[]\n",
    "\n",
    "words_to_explore= ['woman', 'man', 'queen', 'king', 'human', 'person', 'girl', 'child', 'boy', 'salad', 'lettuce', 'tomato', 'soup', 'turnip', 'arugula', 'pepper', 'greens', 'barley', 'bean', 'stew', 'carrot']\n",
    "\n",
    "for i in words_to_explore:   \n",
    "    if my_word_list not in my_word_list:\n",
    "        my_word_list.append(i)\n",
    "        my_word_vectors.append(currentmodel.wv[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR, try the most feminine and most masculine words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_word_list=[]\n",
    "my_word_vectors=[]\n",
    "label=[]\n",
    "\n",
    "for i in currentmodel.wv.most_similar(positive=['woman'], negative=['man'], topn=30):   #30 most feminine words\n",
    "    if my_word_list not in my_word_list:\n",
    "        my_word_list.append(i[0])\n",
    "        my_word_vectors.append(currentmodel.wv[i[0]])\n",
    "        label.append('fem')\n",
    "\n",
    "for i in currentmodel.wv.most_similar(positive=['man'], negative=['woman'], topn=30):   #30 most masculine words\n",
    "    if my_word_list not in my_word_list:\n",
    "        my_word_list.append(i[0])\n",
    "        my_word_vectors.append(currentmodel.wv[i[0]])\n",
    "        label.append('masc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#review of tsne: http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "#modified code from https://www.kaggle.com/jeffd23/visualizing-word-vectors-with-t-sne/code\n",
    "\n",
    "def tsne_plot(words, vectors, iterations, seed, title): \n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    tsne_model = TSNE(perplexity=5, n_components=2, init='pca', n_iter=iterations, random_state=seed) #you may need to tune these, epsecially the perplexity. #Use PCA to reduce dimensionality to 2-D, an \"X\" and a \"Y \n",
    "    new_values = tsne_model.fit_transform(vectors)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(10, 10)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(words[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.ylabel(\"Latent Dimension 1\") #Some pyplot reminders: https://matplotlib.org/users/pyplot_tutorial.html\n",
    "    plt.xlabel(\"Latent Dimension 2\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAJcCAYAAAB0Y+mpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEREREZ9QsBMRERHxCQU7EREREZ/4/1QA6yIRY8IGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ccc6428400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsne_plot(my_word_list, my_word_vectors, 3000, 23,  \"TSNE Visualization of Word-Vectors\") #don't use too many words, won't finish running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your plot doesn't look meaninful, want to see how robust the patterns are, or you want to understand TSNE better, try tuning parameters (especially the perplexity) and take a look at this great [article](https://distill.pub/2016/misread-tsne/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
