{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Alternate Strategy- Extract WordVectors for ML and Neural Net Experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alina Arseniev\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Alina Arseniev\\\\Dropbox\\\\GSRM\\\\LexisNexis Data\\\\ScaleClassificationApproaches'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "np.set_printoptions(threshold=np.inf) #do this if you want to print full output\n",
    "import csv\n",
    "from collections import Counter\n",
    "import os\n",
    "cwd= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#currentmodel = gensim.models.Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "#currentmodel=  Word2Vec.load(\"modelA_ALLYEARS_300dim_10CW\") #load up the word2vec model of choice, model 2 used for all decision tree training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "currentmodel=  Word2Vec.load(\"C:\\\\Users\\\\Alina Arseniev\\\\Dropbox\\\\GSRM\\\\LexisNexis Data\\\\BootStrapped90percentModels\\\\modelA_ALLYEARS_bigrams_9A_1\") #load up the word2vec model of choice, model 2 used for all decision tree training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Code below extracts just the word-vectors for feminine words and masculine words (training set, validation set, and testing set for each scale, then obesity-keywords). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gendertrain_words3=[ \n",
    "            'madame', 'ladies', 'lady',\n",
    "          'mother', 'mothers', 'mom', 'mama', 'granddaughter', 'daughter', 'daughters', 'aunt', 'godmother', \n",
    "          'grandma', 'grandmothers', 'grandmother', 'sister', 'sisters', 'aunts', 'stepmother', 'granddaughters', 'niece',\n",
    "        'fiancee', 'ex_girlfriend', 'girlfriends', 'wife', 'wives', 'girlfriend', 'bride', 'brides', 'widow',\n",
    "           'twin_sister', 'younger_sister', 'teenage_girl', 'teenage_girls', 'eldest_daughter','estranged_wife', 'schoolgirl',\n",
    "        'businesswoman', 'congresswoman' , 'chairwoman', 'councilwoman', 'waitress', 'hostess', 'convent', 'heiress', \n",
    "           'saleswoman', 'queen', 'queens', 'princess', 'nun' , 'nuns', 'heroine', 'actress', 'actresses', 'uterus', 'vagina', 'ovarian_cancer',\n",
    "        'maternal', 'maternity', 'motherhood', 'sisterhood', 'girlhood', 'matriarch', 'sorority', 'mare', 'hen', 'hens', 'filly', 'fillies',\n",
    "          'deer', 'older_sister', 'oldest_daughter', 'stepdaughter', 'pink', 'cute', 'dependent', 'nurturing', 'hysterical', 'bitch',  'dance', 'dancing', \n",
    "               'sir', 'guys', 'gentleman','father', 'fathers', 'dad', 'papa', 'grandson' , 'son', 'sons', 'uncle', 'godfather', \n",
    "        'grandpa', 'grandfathers', 'grandfather', 'brother', 'brothers' , 'uncles', 'stepfather', 'grandsons', 'nephew',\n",
    "           'fiance', 'ex_boyfriend', 'boyfriends', 'husband', 'husbands', 'boyfriend', 'groom', 'grooms', 'widower',\n",
    "            'twin_brother', 'younger_brother', 'teenage_boy', 'teenage_boys', 'eldest_son', 'estranged_husband', 'schoolboy',\n",
    "            'businessman', 'congressman', 'chairman', 'councilman', 'waiter', 'host', 'monastery', 'heir', 'salesman', \n",
    "            'king', 'kings', 'prince', 'monk', 'monks', 'hero', 'actor', 'actors', 'prostate', 'penis', 'prostate_cancer', \n",
    "        'paternal', 'paternity', 'fatherhood', 'brotherhood', 'boyhood', 'patriarch', 'fraternity', 'stallion', 'rooster', 'roosters', 'colt',\n",
    "           'colts', 'bull', 'older_brother', 'oldest_son', 'stepson', 'blue' ,'manly', 'independent', 'aggressive', 'angry', 'jerk', 'wrestle', 'wrestling'  ]\n",
    "\n",
    "#this is adding some more implicit (and thus arguably labeled, too) gender words for training, and removing some of the explicit ones\n",
    "gendertrain_words2=[ 'girl', 'girls', 'her', 'hers', 'herself', 'she', \n",
    "            'lady', 'gal', 'gals', 'madame', 'ladies', 'lady',\n",
    "          'mother', 'mothers', 'mom', 'moms', 'mommy', 'mama', 'ma', 'granddaughter', 'daughter', 'daughters', 'aunt', 'godmother', \n",
    "          'grandma', 'grandmothers', 'grandmother', 'sister', 'sisters', 'aunts', 'stepmother', 'granddaughters', 'niece',\n",
    "        'fiancee', 'ex_girlfriend', 'girlfriends', 'wife', 'wives', 'girlfriend', 'bride', 'brides', 'widow',\n",
    "           'twin_sister', 'younger_sister', 'teenage_girl', 'teenage_girls', 'eldest_daughter','estranged_wife', 'schoolgirl',\n",
    "        'businesswoman', 'congresswoman' , 'chairwoman', 'councilwoman', 'waitress', 'hostess', 'convent', 'heiress', \n",
    "           'saleswoman', 'queen', 'queens', 'princess', 'nun' , 'nuns', 'heroine', 'actress', 'actresses', 'uterus', 'vagina', 'ovarian_cancer',\n",
    "        'maternal', 'maternity', 'motherhood', 'sisterhood', 'girlhood', 'matriarch', 'sorority', 'mare', 'hen', 'hens', 'filly', 'fillies',\n",
    "          'deer', 'older_sister', 'oldest_daughter', 'stepdaughter', 'pink',  'cute', 'dependent', 'nurturing', 'hysterical', 'bitch',  'dance', 'dancing', \n",
    "                'boy', 'boys', 'him', 'his', 'himself', 'he', 'guy', 'dude',\n",
    "            'dudes', 'sir', 'guys', 'gentleman','father', 'fathers', 'dad', 'dads', 'daddy', 'papa', 'pa', 'grandson' , 'son', 'sons', 'uncle', 'godfather', \n",
    "        'grandpa', 'grandfathers', 'grandfather', 'brother', 'brothers' , 'uncles', 'stepfather', 'grandsons', 'nephew',\n",
    "           'fiance', 'ex_boyfriend', 'boyfriends', 'husband', 'husbands', 'boyfriend', 'groom', 'grooms', 'widower',\n",
    "            'twin_brother', 'younger_brother', 'teenage_boy', 'teenage_boys', 'eldest_son', 'estranged_husband', 'schoolboy',\n",
    "            'businessman', 'congressman', 'chairman', 'councilman', 'waiter', 'host', 'monastery', 'heir', 'salesman', \n",
    "            'king', 'kings', 'prince', 'monk', 'monks', 'hero', 'actor', 'actors', 'prostate', 'penis', 'prostate_cancer', \n",
    "        'paternal', 'paternity', 'fatherhood', 'brotherhood', 'boyhood', 'patriarch', 'fraternity', 'stallion', 'rooster', 'roosters', 'colt',\n",
    "           'colts', 'bull', 'older_brother', 'oldest_son', 'stepson', 'blue' ,'manly', 'independent', 'aggressive', 'angry', 'jerk', 'wrestle', 'wrestling'  ]\n",
    "\n",
    "gendertrain_words=['womanly', 'my_wife', 'my_mom', 'my_grandmother', 'woman', 'women', 'girl', 'girls', 'her', 'hers', 'herself', 'she', \n",
    "            'lady', 'gal', 'gals', 'madame', 'ladies', 'lady',\n",
    "          'mother', 'mothers', 'mom', 'moms', 'mommy', 'mama', 'ma', 'granddaughter', 'daughter', 'daughters', 'aunt', 'godmother', \n",
    "          'grandma', 'grandmothers', 'grandmother', 'sister', 'sisters', 'aunts', 'stepmother', 'granddaughters', 'niece',\n",
    "          'fiancee', 'ex_girlfriend', 'girlfriends', 'wife', 'wives', 'girlfriend', 'bride', 'brides', 'widow',\n",
    "           'twin_sister', 'younger_sister', 'teenage_girl', 'teenage_girls', 'eldest_daughter','estranged_wife', 'schoolgirl',\n",
    "          'businesswoman', 'congresswoman' , 'chairwoman', 'councilwoman', 'waitress', 'hostess', 'convent', 'heiress', \n",
    "           'saleswoman', 'queen', 'queens', 'princess', 'nun' , 'nuns', 'heroine', 'actress', 'actresses', 'uterus', 'vagina', 'ovarian_cancer',\n",
    "           'maternal', 'maternity', 'motherhood', 'sisterhood', 'girlhood', 'matriarch', 'sorority', \n",
    "         'older_sister', 'oldest_daughter', 'stepdaughter',\n",
    "                    'manly', 'my_husband', 'my_dad','my_grandfather', 'man', 'men', 'boy', 'boys', 'him', 'his', 'himself', 'he', 'guy', 'dude',\n",
    "            'dudes', 'sir', 'guys', 'gentleman','father', 'fathers', 'dad', 'dads', 'daddy', 'papa', 'pa', 'grandson' , 'son', 'sons', 'uncle', 'godfather', \n",
    "           'grandpa', 'grandfathers', 'grandfather', 'brother', 'brothers' , 'uncles', 'stepfather', 'grandsons', 'nephew',\n",
    "           'fiance', 'ex_boyfriend', 'boyfriends', 'husband', 'husbands', 'boyfriend', 'groom', 'grooms', 'widower',\n",
    "            'twin_brother', 'younger_brother', 'teenage_boy', 'teenage_boys', 'eldest_son', 'estranged_husband', 'schoolboy',\n",
    "            'businessman', 'congressman', 'chairman', 'councilman', 'waiter', 'host', 'monastery', 'heir', 'salesman', \n",
    "            'king', 'kings', 'prince', 'monk', 'monks', 'hero', 'actor', 'actors', 'prostate', 'penis', 'prostate_cancer', \n",
    "           'paternal', 'paternity', 'fatherhood', 'brotherhood', 'boyhood', 'patriarch', 'fraternity', \n",
    "           'older_brother', 'oldest_son', 'stepson']\n",
    "\n",
    "genderinteresting_words= [ 'blonde', 'blond', 'politician', 'programmer', 'nurse', 'doctor', 'estrogen', 'testosterone', 'soldier', 'army', 'drafted', 'military', \n",
    "                          'pregnancy', 'pregnant', 'beard', 'nanny', 'pink', 'lipstick', 'mustache', 'bride', 'groom', 'lady', 'guy', 'sewing', 'modeling', 'actress', 'actor', 'genius', 'brilliant']\n",
    "\n",
    "genderinteresting_words_implicit=['petite', 'cooking', 'graceful',  'housework', 'soft', 'whisper', 'flirtatious', 'accepting', 'blonde', 'blond', 'doll', 'dolls','nurse',  'estrogen', 'lipstick','pregnant', 'nanny', 'pink', \n",
    "                                'sewing', 'modeling', 'dainty', 'gentle', 'children','pregnancy', 'nurturing', 'depressed', 'nice', 'emotional','depression', 'home', 'kitchen', 'quiet', 'submissive',\n",
    "                                'soldier', 'army', 'drafted', 'military',   'beard', 'mustache', 'genius', 'engineering', 'math', \n",
    "                                'brilliant', 'strong', 'strength',  'politician', 'programmer','doctor', 'sexual', 'aggressive', \n",
    "                                'testosterone', 'tall', 'competitive', 'big', 'powerful', 'mean', 'sports', 'fighting', 'confident', 'rough', 'loud', 'worldly',\n",
    "                                  'experienced', 'insensitive', 'ambitious', 'dominant']\n",
    "\n",
    "gendertest_words=['goddess', 'single_mother', 'girlish', 'feminine', 'young_woman', 'little_girl', 'ladylike', 'my_mother', \n",
    "           'teenage_daughter', 'mistress', 'great_grandmother', 'adopted_daughter', 'femininity', 'motherly', 'matronly', \n",
    "           'showgirl', 'housewife', 'vice_chairwoman', 'co_chairwoman', 'spokeswoman', 'governess', 'divorcee', 'spinster', \n",
    "           'maid', 'countess', 'pregnant_woman', 'landlady', 'seamstress', 'young_girl', 'waif', 'femme_fatale','comedienne',\n",
    "            'boyish', 'masculine',  'lad', 'policeman', 'macho', 'gentlemanly', 'machismo',  'teenage_son', \n",
    "            'beau', 'great_grandfather', 'tough_guy', 'masculinity', 'bad_boy', 'spokesman', 'baron', 'adult_male', 'landlord', 'fireman', 'mailman', 'vice_chairman', \n",
    "           'co_chairman','young_man', 'bearded', 'mustachioed', 'con_man', 'homeless_man', 'gent', 'strongman']\n",
    "\n",
    "moraltrain_words= ['good', 'benevolent', 'nice', 'caring', 'conscientious', 'polite', 'fair', 'virtue', 'respect', 'responsible', \n",
    "            'selfless', 'unselfish', 'sincere', 'truthful', 'wonderful', 'justice', 'innocent', 'innocence',\n",
    "           'complement', 'sympathetic', 'virtue', 'right', 'proud', 'pride','respectful', 'appropriate', 'pleasing', 'pleasant', \n",
    "            'pure', 'decent', 'pleasant', 'compassion' , 'compassionate', 'constructive','graceful', 'gentle', 'reliable',\n",
    "           'careful', 'help', 'decent' , 'moral', 'hero', 'heroic', 'heroism', 'honest', 'honesty',\n",
    "           'selfless', 'humility', 'humble', 'generous', 'generosity', 'faithful', 'fidelity', 'worthy', 'tolerant',\n",
    "            'obedient', 'pious', 'saintly', 'angelic', 'virginal', 'sacred', 'reverent', 'god', 'hero', 'heroic', \n",
    "            'forgiving', 'saintly','holy', 'chastity', 'grateful', 'considerate', 'humane', \n",
    "            'trustworthy', 'loyal', 'loyalty', 'empathetic', 'empathy', 'clean', 'straightforward', 'pure',\n",
    "                    'bad', 'evil', 'mean', 'uncaring', 'lazy', 'rude', 'unfair', 'sin', 'disrespect','irresponsible', \n",
    "           'self_centered', 'selfish', 'insincere', 'lying', 'horrible', 'injustice', 'guilty', 'guilt', \n",
    "            'insult', 'unsympathetic', 'vice', 'wrong', 'ashamed', 'shame', 'disrespectful', 'inappropriate', 'vulgar', 'crude', \n",
    "            'dirty', 'obscene', 'offensive', 'cruelty','brutal', 'destructive', 'rude', 'harsh', 'unreliable',\n",
    "            'careless', 'harm', 'indecent', 'immoral', 'coward', 'cowardly', 'cowardice', 'dishonest', 'dishonesty',\n",
    "            'narcissistic', 'arrogance', 'arrogant', 'greedy', 'greed', 'betray', 'betrayal', 'unworthy', 'intolerant', \n",
    "             'defiant', 'rebellious', 'demonic','devilish', 'promiscuous', 'profane', 'irreverent', 'devil', 'villain', 'villainous', \n",
    "            'vindictive', 'diabolical', 'unholy', 'promiscuity', 'ungrateful', 'thoughtless', 'inhumane',\n",
    "            'untrustworthy', 'treacherous', 'treachery', 'callous', 'indifference', 'dirty', 'manipulative', 'impure' ]\n",
    "\n",
    "moraltest_words=['great', 'best', 'faith', 'chaste', 'wholesome', 'noble', 'honorable', 'immaculate', 'gracious', \n",
    "           'courteous', 'delightful', 'earnest', 'amiable', 'admirable', 'disciplined', 'patience', 'integrity',\n",
    "            'restraint', 'upstanding', 'diligent', 'dutiful', 'loving', 'righteous','respectable', 'praise', 'devout', 'forthright',\n",
    "            'depraved', 'repulsive', 'repugnant', 'corruption', 'vicious', 'unlawful', 'outrage',  'shameless', 'perverted',\n",
    "            'filthy', 'lewd', 'subversive', 'sinister', 'murderous', 'perverse', \n",
    "           'monstrous', 'homicidal', 'indignant', 'misdemeanor', 'degenerate', 'malevolent', 'illegal','terrorist','terrorism',  \n",
    "             'cheated', 'vengeful', 'culpable','vile', 'hateful', 'abuse', 'abusive', 'criminal', 'deviant']\n",
    "\n",
    "healthtrain_words= ['fertile', 'help_prevent', 'considered_safe', 'safer', 'healthy', 'healthy', 'healthy', 'healthy', 'healthy',\n",
    "            'healthful', 'well_balanced', 'natural', 'healthy', 'athletic','physically_active', 'health',\n",
    "            'health', 'nutritious','nourishing', 'stronger', 'strong','wellness', 'safe', 'nutritious_food','exercise',\n",
    "            'physically_fit', 'unprocessed', 'healthier_foods', 'nutritious_foods', 'nutritious', 'nutritious',\n",
    "           'healthy_eating', 'healthy_diet', 'healthy_diet', 'nourishing', 'nourished', 'regular_exercise', 'safety', 'safe', \n",
    "            'helpful', 'beneficial', \n",
    "            'healthy', 'healthy', 'sturdy', 'lower_risk', 'reduced_risk', 'decreased_risk', 'nutritious_foods', 'whole_grains', 'healthier_foods',\n",
    "            'healthier_foods', 'physically_active', 'physical_activity', 'nourished', 'vitality', 'energetic', 'able_bodied',\n",
    "            'resilience', 'strength', 'less_prone', 'sanitary', 'clean',  'healing', 'heal', 'salubrious', \n",
    "                    'infertile', 'cause_harm','potentially_harmful','riskier', 'unhealthy', 'sick', 'ill', 'frail', 'sickly', \n",
    "            'unhealthful','unbalanced', 'unnatural', 'dangerous', 'sedentary', 'inactive', 'illness', \n",
    "            'sickness', 'toxic', 'unhealthy', 'weaker', 'weak', 'illness', 'unsafe', 'unhealthy_foods', 'sedentary',\n",
    "            'inactive', 'highly_processed', 'processed_foods', 'junk_foods', 'unhealthy_foods', 'junk_foods',\n",
    "           'processed_foods', 'processed_foods', 'fast_food', 'unhealthy_foods', 'deficient', 'sedentary', 'hazard','hazardous', \n",
    "            'harmful', 'injurious', \n",
    "            'chronically_ill', 'seriously_ill', 'frail', 'higher_risk', 'greater_risk', 'increased_risk', 'fried_foods', 'fried_foods',\n",
    "            'fatty_foods', 'sugary_foods', 'sedentary', 'physical_inactivity', 'malnourished', 'lethargy', 'lethargic', 'disabled',\n",
    "            'susceptibility', 'weakness', 'more_susceptible', 'filthy', 'dirty', 'harming', 'hurt', 'deleterious'\n",
    "              ]\n",
    "\n",
    "healthtest_words=[ 'balanced_diet', 'healthfulness', 'fiber', 'jogging', 'stopping_smoking', 'vigor', \n",
    "          'active', 'fit', 'flourishing', 'sustaining', 'hygienic', 'hearty', 'enduring', 'energized', 'wholesome', \n",
    "           'holistic', 'healed', 'fitter', 'health_conscious', 'more_nutritious', 'live_longer',  'exercising_regularly',\n",
    "           'healthier_choices', 'healthy_habits', 'healthy_lifestyle', 'healthful_eating', 'immune', \n",
    "            'deadly', 'diseased',  'adverse', 'risky', 'fatal', 'filthy', 'epidemic', 'crippling', 'carcinogenic', 'carcinogen',\n",
    "           'crippled', 'afflicted', 'contaminated', 'fatigued', 'detrimental', 'bedridden', 'incurable', 'hospitalized',\n",
    "           'infected', 'ailing', 'debilitated', 'poisons', 'disabling', 'life_threatening', 'debilitating', \n",
    "           'chronic_illness', 'artery_clogging', 'hypertension','disease', 'stroke',\n",
    "            'plague', 'fatty', 'smoking'] \n",
    "\n",
    "sestrain_words=['wealth', 'wealthier', 'wealthiest', 'affluence', 'prosperity', 'wealthy', 'affluent', 'affluent', 'prosperous',\n",
    "                'prosperous','prosperous','disposable_income',  'wealthy','suburban','luxurious','upscale','upscale', 'luxury', \n",
    "                'richest', 'privileged', 'moneyed', 'privileged', 'privileged', 'educated', 'employed', \n",
    "                'elite', 'upper_income', 'upper_class', 'employment', 'riches', 'millionaire', 'aristocrat', 'college_educated',\n",
    "                'abundant', 'lack', 'luxury', 'profitable', 'profit', 'well_educated', 'elites', 'heir', 'well_heeled', \n",
    "                'white_collar', 'higher_incomes', 'bourgeois', 'fortunate', 'successful','economic_growth', 'prosper', 'suburbanites', \n",
    "                        'poverty', 'poorer', 'poorest', 'poverty', 'poverty', 'impoverished', 'impoverished',  'needy',  'impoverished',\n",
    "                 'poor', 'needy', 'broke', 'needy', 'slum', 'ghetto', 'slums', 'ghettos', 'poor_neighborhoods', \n",
    "                'poorest', 'underserved', 'disadvantaged','marginalized', 'underprivileged', 'uneducated', 'unemployed', \n",
    "                'marginalized', 'low_income', 'underclass','unemployment', 'rags', 'homeless', 'peasant', 'college_dropout', \n",
    "                'lacking', 'abundance', 'squalor', 'bankrupt', 'debt', 'illiterate' ,'underclass', 'orphan',  'destitute', \n",
    "                'blue_collar', 'low_income', 'neediest', 'less_fortunate', 'unsuccessful', 'economic_crisis', 'low_wage', 'homeless'\n",
    "                  ]\n",
    "\n",
    "sestest_words= ['rich', 'billionaire', 'banker',  'fortune', 'heiress', 'cosmopolitan', 'ornate', 'entrepreneur', 'sophisticated',\n",
    "                'aristocratic', 'investor', 'highly_educated', 'better_educated',  'splendor', \n",
    "               'businessman', 'opulent', 'multimillionaire', 'philanthropist', 'estate', 'estates', 'chateau', 'fortunes', \n",
    "               'financier', 'young_professionals','tycoon', 'baron', 'grandeur', 'magnate', \n",
    "               'investment_banker', 'venture_capitalist', 'upwardly_mobile', 'highly_skilled', 'yuppies', 'genteel',\n",
    "                         'homelessness', 'ruin', 'ruined', 'downtrodden', 'less_affluent',\n",
    "                'housing_project', 'homeless_shelters', 'indigent', 'jobless', 'welfare',  \n",
    "                'temporary_shelters','housing_projects', 'subsidized_housing', 'starving', 'beggars', 'orphanages',\n",
    "                'dispossessed', 'uninsured', 'welfare_recipients', 'food_stamps', \n",
    "                'malnutrition',  'underemployed', 'disenfranchised', 'servants', 'displaced', 'poor_families'] \n",
    "\n",
    "obesity_words= ['obese', 'obesity', 'diabetic', 'diabetes', 'weight', 'overweight', 'thin', 'slender', 'burly',\n",
    "                'muscular', 'diet', 'dieting', 'health', 'healthy', 'unhealthy', 'fat', 'anorexic', 'anorexia', 'bulimia', \n",
    "                'beautiful', 'handsome', 'overeating', 'exercise', 'sedentary', 'bulimic', 'morbidly_obese', 'normal_weight',\n",
    "                'seriously_overweight'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 60\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(len(gendertrain_words), len(gendertest_words)) \n",
    "\n",
    "print(list(set(gendertrain_words) & set(gendertest_words)))\n",
    "cnt = Counter(gendertest_words)\n",
    "print([k for k, v in cnt.items() if v > 1]) #if present in the list more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "print(len(genderinteresting_words_implicit))\n",
    "\n",
    "for i in genderinteresting_words_implicit:\n",
    "    try:\n",
    "        x= currentmodel[i]\n",
    "    except KeyError:\n",
    "        print(i,  'was not in this Word2Vec models vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 60\n",
      "[]\n",
      "['virtue', 'selfless', 'pleasant', 'pure', 'decent', 'hero', 'heroic', 'saintly', 'rude', 'dirty']\n"
     ]
    }
   ],
   "source": [
    "print(len(moraltrain_words), len(moraltest_words)) \n",
    "print(list(set(moraltrain_words) & set(moraltest_words)))\n",
    "cnt = Counter(moraltrain_words)\n",
    "print([k for k, v in cnt.items() if v > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 60\n",
      "[]\n",
      "['healthy', 'physically_active', 'health', 'nutritious', 'nourishing', 'safe', 'healthier_foods', 'nutritious_foods', 'healthy_diet', 'nourished', 'unhealthy', 'frail', 'sedentary', 'inactive', 'illness', 'unhealthy_foods', 'processed_foods', 'junk_foods', 'fried_foods']\n"
     ]
    }
   ],
   "source": [
    "print(len(healthtrain_words),  len(healthtest_words)) \n",
    "print(list(set(healthtrain_words) & set(healthtest_words)))\n",
    "cnt = Counter(healthtrain_words)\n",
    "print([k for k, v in cnt.items() if v > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 60\n",
      "[]\n",
      "['wealthy', 'affluent', 'prosperous', 'upscale', 'luxury', 'privileged', 'poverty', 'poorest', 'impoverished', 'needy', 'marginalized', 'low_income', 'underclass', 'homeless']\n"
     ]
    }
   ],
   "source": [
    "print(len(sestrain_words), len(sestest_words)) \n",
    "print(list(set(sestrain_words) & set(sestest_words)))\n",
    "cnt = Counter(sestrain_words)\n",
    "print([k for k, v in cnt.items() if v > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in gendertrain_words:\n",
    "    try:\n",
    "        x= currentmodel[i]\n",
    "    except KeyError:\n",
    "        print(i,  'was not in this Word2Vec models vocab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Function \"class_word_data\" to get data needed (training word and testing word word-vectors, word, and expected classes)\n",
    "and then write to a CSV. Takes the input of the train_words, test_words, and file name desired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_word_data(train_words, test_words, scale, filename):\n",
    "    #first make vector of true classes for training set\n",
    "    train_classes=np.repeat(1, len(train_words)*.5).tolist() #1 is feminine/moral/healthy/rich\n",
    "    masc1=np.repeat(0, len(train_words)*.5).tolist() #0 is masculine/immoral/unhealthy/poor\n",
    "    for i in masc1:\n",
    "        train_classes.append(i)\n",
    "\n",
    "    #make long list of vectors of training words, which are split half/half\n",
    "    train_vecs=[]\n",
    "    for i in range(0, len(train_words)):\n",
    "        try:\n",
    "            train_vecs.append(currentmodel[train_words[i]])  \n",
    "        except:\n",
    "            train_vecs.append('nope') \n",
    "    #make vector of true classes for testing set, which are split differently...\n",
    "    if scale=='gender':\n",
    "        test_classes=np.repeat(1, 32).tolist() #1 is feminine\n",
    "        masc2=np.repeat(0, 28).tolist() #0 is masculine\n",
    "        for i in masc2:\n",
    "            test_classes.append(i)    \n",
    "    elif scale == 'moral':\n",
    "        test_classes=np.repeat(1, 27 ).tolist() #1 is feminine\n",
    "        masc2=np.repeat(0,33).tolist() #0 is masculine\n",
    "        for i in masc2:\n",
    "            test_classes.append(i)\n",
    "    elif scale== 'health':\n",
    "        test_classes=np.repeat(1, 27).tolist() #1 is feminine\n",
    "        masc2=np.repeat(0, 33 ).tolist() #0 is masculine\n",
    "        for i in masc2:\n",
    "            test_classes.append(i)\n",
    "    elif scale== 'ses':\n",
    "        test_classes=np.repeat(1, 34).tolist() #1 is feminine\n",
    "        masc2=np.repeat(0, 26).tolist() #0 is masculine\n",
    "        for i in masc2:\n",
    "            test_classes.append(i)\n",
    "    else:\n",
    "        print('not clear which set of words to use')\n",
    "    \n",
    "    #make long list of vectors of testing words\n",
    "    test_vecs=[]\n",
    "    for i in range(0, len(test_words)):\n",
    "        try:\n",
    "            test_vecs.append(currentmodel[test_words[i]])  #make long list of vectors of testing words\n",
    "        except:\n",
    "            test_vecs.append('nope') \n",
    "        \n",
    "    #write the above four pieces of data to a CSV\n",
    "    b = open(filename, 'w') \n",
    "    a = csv.writer(b)\n",
    "    a.writerow(train_words)\n",
    "    a.writerow(train_classes)\n",
    "    for i in range(0,len(train_vecs)):\n",
    "        a.writerow(train_vecs[i])\n",
    "    a.writerow(test_words)\n",
    "    a.writerow(test_classes)\n",
    "    for i in range(0,len(test_vecs)):\n",
    "        a.writerow(test_vecs[i])\n",
    "    b.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_word_data(gendertrain_words2, gendertrain_words3, 'gender',  'Word_Vectors_gender_ALLYEARS_30010CW_loosertrainingwords.csv') #run this for gender words, moral words, health words, and SES words. Easiest to keep track of if run separately and CSVs are labeled accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write CSV with Obesity-keywords wordvectors\n",
    "\n",
    "obesity_vecs=[]\n",
    "for i in range(0, len(obesity_words)):\n",
    "    try:\n",
    "        obesity_vecs.append(currentmodel[obesity_words[i]])  #make long list of vectors of testing words\n",
    "    except:\n",
    "        obesity_vecs.append('nope')\n",
    "\n",
    "b = open('Word_Vectors_Obesity_ALLYEARS_GOOGLE.csv', 'w') \n",
    "a = csv.writer(b)\n",
    "a.writerow(obesity_words)\n",
    "for i in range(0,len(obesity_vecs)):\n",
    "    a.writerow(obesity_vecs[i])\n",
    "b.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write CSV with gender-interesting keywords wordvectors\n",
    "\n",
    "stereo_vecs=[]\n",
    "for i in range(0, len(genderinteresting_words_implicit)):\n",
    "    try:\n",
    "        stereo_vecs.append(currentmodel[genderinteresting_words_implicit[i]])  #make long list of vectors of testing words\n",
    "    except:\n",
    "        stereo_vecs.append('nope')\n",
    "\n",
    "b = open('Word_Vectors_STEREOTYPES_broad.csv', 'w') \n",
    "a = csv.writer(b)\n",
    "a.writerow(genderinteresting_words_implicit)\n",
    "for i in range(0,len(stereo_vecs)):\n",
    "    a.writerow(stereo_vecs[i])\n",
    "b.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Neural Network using Gender Training Words (experiment), using sample code from http://iamtrask.github.io/2015/07/12/basic-python-network/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.98        85\n",
      "          1       0.98      0.99      0.98        85\n",
      "\n",
      "avg / total       0.98      0.98      0.98       170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_classes,predictions17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = open('test7.csv', 'w') \n",
    "a = csv.writer(b)\n",
    "a.writerow(train_words)\n",
    "a.writerow(train_classes)\n",
    "a.writerow(predictions3)\n",
    "a.writerow(predictions5)\n",
    "a.writerow(predictions7)\n",
    "a.writerow(predictions9)\n",
    "a.writerow(predictions11)\n",
    "a.writerow(predictions13)\n",
    "a.writerow(predictions15)\n",
    "a.writerow(predictions17)\n",
    "b.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
